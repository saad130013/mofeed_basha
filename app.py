import streamlit as st
import pandas as pd
import fitz  # PyMuPDF
import requests
import os
from langchain.llms import LlamaCpp
from langchain.chains import load_qa_chain
from langchain.docstore.document import Document

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(
    page_title="Ù…ÙÙŠØ¯ Ø¨Ø§Ø´Ø§ - Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ",
    layout="wide",
    page_icon="ğŸ¤–",
    menu_items={"About": "ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© ÙØ±ÙŠÙ‚ Ù…ÙÙŠØ¯ Ø¨Ø§Ø´Ø§"}
)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø¨Ø¯ÙˆÙ† Ù…Ù„Ù config.yml)
MODEL_CONFIG = {
    "url": "https://drive.usercontent.google.com/download?id=11ARnFAX2I6a-OSSOTtPqvaP41qwe4UHw&export=download",
    "path": "model.bin",
    "settings": {
        "temperature": 0.1,
        "max_tokens": 512,
        "n_ctx": 2048,
        "verbose": False
    }
}

# â”€â”€â”€ ÙˆØ¸Ø§Ø¦Ù Ø£Ø³Ø§Ø³ÙŠØ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_model():
    """ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Google Drive"""
    if not os.path.exists(MODEL_CONFIG["path"]):
        with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
            try:
                response = requests.get(MODEL_CONFIG["url"], stream=True)
                with open(MODEL_CONFIG["path"], "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
            except Exception as e:
                st.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {e}")
                st.stop()

def process_file(uploaded_file):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©"""
    if uploaded_file.type == "application/pdf":
        with fitz.open(stream=uploaded_file.read(), filetype="pdf") as doc:
            return "\n".join([page.get_text() for page in doc])
    else:
        df = pd.read_excel(uploaded_file)
        return df.to_string()

# â”€â”€â”€ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ¤– Ù…ÙÙŠØ¯ Ø¨Ø§Ø´Ø§ - Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ")
uploaded_file = st.file_uploader("ğŸ“ Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF Ø£Ùˆ Excel", type=["pdf", "xlsx"])

if uploaded_file:
    text_data = process_file(uploaded_file)
    st.subheader("ğŸ“„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
    st.text_area("Ø§Ù„Ù†Øµ", text_data, height=250)

    if st.text_input("ğŸ’¬ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ:"):
        download_model()  # ØªØ£ÙƒÙŠØ¯ ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        
        llm = LlamaCpp(
            model_path=MODEL_CONFIG["path"],
            **MODEL_CONFIG["settings"]
        )
        
        chain = load_qa_chain(llm, chain_type="stuff")
        docs = [Document(page_content=text_data)]
        
        try:
            answer = chain.run(input_documents=docs, question=st.session_state.question)
            st.subheader("âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
            st.write(answer)
        except Exception as e:
            st.error(f"âš ï¸ Ø®Ø·Ø£: {str(e)}")
else:
    st.info("ğŸ‘† Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ù…Ù„Ù Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
